{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key notes\n",
    "\n",
    "\n",
    "运行前请修改一下路径名或参数值：\n",
    "\n",
    "[1]base_path = \"./data/whale/train_full/\" ，原始train image的存放路径\n",
    "\n",
    "[2]data = pd.read_csv('./data/whale/train.csv')，train.csv的存放路径\n",
    "\n",
    "[3]train_files = glob.glob(\"./data/whale/train_full/*.jpg\")，原始train image的存放路径\n",
    "\n",
    "[4]test_files = glob.glob(\"./data/whale/test/*.jpg\")，原始test image的存放路径\n",
    "\n",
    "[5]最后会在当前目录下生成一个sub_triplet_loss.csv预测文件，即kaggle规定的submission文件\n",
    "\n",
    "[6]如果laptop运行，GPU内存不到8G，有可能会发生OOM溢出，可以适当减少batch_size\n",
    "\n",
    "\n",
    "\n",
    "模型要点：\n",
    "\n",
    "1.主框架模型时siamese + triplet loss, 求每个image的embedding（长度为50的vector）时用了resNet50模型\n",
    "\n",
    "2.triplet loss使用了Bayesian Personalized Ranking loss\n",
    "\n",
    "3.预处理只做了resize to (256, 256)和convert to RGB, 以及小概率(10%)的fliplr，没有做augment\n",
    "\n",
    "4.挑选triplet的时候没有刻意去挑选（像andrew ng的video和那篇paper里面说的那样，需要刻意去挑选，以提升性能。\n",
    "\n",
    "5.在生产训练batch的时候，用了generator + yield，所有batch的生成都是on the fly，大大减少了memory的消耗\n",
    "\n",
    "6.模型训练完之后，将所有的train images和test images的embedding都计算出来，在embedding（长度只有50）的基础上再做test images的预测，这样大大提升了预测速度\n",
    "\n",
    "7.预测用了knn算法，最后选取最近的5个class id\n",
    "\n",
    "8.因为new whale有大概率出现（9850个train images出现了810次），这里强制把new whale在knn的distance设置为0.1（有待商榷）\n",
    "\n",
    "9.注意建模训练的时候，new_whale的样本是没有参与train的\n",
    "\n",
    "总结：最粗糙暴力的方法，最后的MAP有0.42左右，排名还挺高，可以考虑在这个基础上优化。\n",
    "\n",
    "优化方向：\n",
    "\n",
    "1.preprocessing\n",
    "\n",
    "2.augmentation\n",
    "\n",
    "3.the way to choose triplet\n",
    "\n",
    "4.the knn default distance for new_whale 0.1 ??\n",
    "\n",
    "5.make use of the test images, for example autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part of the code is from https://github.com/maciejkula/triplet_recommendations_keras\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Flatten, Input, merge\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, GlobalMaxPooling2D\n",
    "import glob\n",
    "from PIL import Image\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, \\\n",
    "    GlobalMaxPool2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from sklearn.neighbors import NearestNeighbors  \n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GPU_num = 4\n",
    "batch_size = 64\n",
    "input_shape = (256, 256)\n",
    "base_path = \"./data/whale/train_full/\"\n",
    "\n",
    "def read_and_resize_all_images():\n",
    "    train_files = glob.glob(\"./data/whale/train_full/*.jpg\")\n",
    "\n",
    "    image_arrays = []\n",
    "    for filepath in train_files:\n",
    "        im = Image.open((filepath)).convert('RGB')\n",
    "        im = im.resize(input_shape)\n",
    "        im_array = np.array(im, dtype=\"uint8\")[..., ::-1] #这个是对RGB进行逆序？？\n",
    "        image_arrays.append(np.array(im_array / (np.max(im_array)+ 0.001), dtype=\"float32\"))\n",
    "    \n",
    "    path_imageArray_mapping = {k:v for k, v in zip(train_files, image_arrays)}\n",
    "    return path_imageArray_mapping\n",
    "\n",
    "path_imageArray_mapping = read_and_resize_all_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sample_gen(object):\n",
    "    def __init__(self, file_class_mapping, other_class = \"new_whale\"):\n",
    "        self.file_class_mapping= file_class_mapping\n",
    "        self.class_to_list_files = defaultdict(list)\n",
    "        self.list_other_class = []\n",
    "        self.list_all_files = list(file_class_mapping.keys())\n",
    "        self.range_all_files = list(range(len(self.list_all_files)))\n",
    "\n",
    "        for file, class_ in file_class_mapping.items():\n",
    "            if class_ == other_class:\n",
    "                self.list_other_class.append(file)\n",
    "            else:\n",
    "                self.class_to_list_files[class_].append(file)\n",
    "\n",
    "#       注意这里的去除了重复class id\n",
    "        self.list_classes = list(set(self.file_class_mapping.values()))\n",
    "        self.range_list_classes= range(len(self.list_classes))#包含了new_whale\n",
    "#       每个class（Id）的比重，相当于直方图  \n",
    "        self.class_weight = np.array([len(self.class_to_list_files[class_]) for class_ in self.list_classes]) * 1.0\n",
    "#         self.class_weight = self.class_weight/np.sum(self.class_weight)\n",
    "        \n",
    "#       new_whale的class_weight是0\n",
    "        self.class_weight /= self.class_weight.sum()\n",
    "        print \"sum=\", self.class_weight.sum()\n",
    "\n",
    "#   这个函数只是返回一个triplet样例\n",
    "    def get_sample(self):\n",
    "#       按class id比重抽取一个样本，因为new_whale的weight是0，所以不会被抽取到\n",
    "        class_idx = np.random.choice(self.range_list_classes, 1, p=self.class_weight)[0]\n",
    "#       对这种class id的，抽取两个样本images (如果某个class只有一个样本，那么返回的是两个一样的image)\n",
    "        examples_class_idx = np.random.choice(range(len(self.class_to_list_files[self.list_classes[class_idx]])), 2)\n",
    "#       注意这两个样本属于同一个class\n",
    "        positive_example_1, positive_example_2 = \\\n",
    "            self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[0]],\\\n",
    "            self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[1]]\n",
    "\n",
    "#       提取一个跟positive_example_1不同class的样本\n",
    "        negative_example = None\n",
    "        while negative_example is None or self.file_class_mapping[negative_example] == \\\n",
    "                self.file_class_mapping[positive_example_1]:\n",
    "            negative_example_idx = np.random.choice(self.range_all_files, 1)[0]\n",
    "            negative_example = self.list_all_files[negative_example_idx]\n",
    "        return positive_example_1, negative_example, positive_example_2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 就是返回了y_pred的平均值\n",
    "def identity_loss(y_true, y_pred):\n",
    "\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "# Bayesian Personalized Ranking loss\n",
    "def bpr_triplet_loss(X):\n",
    "\n",
    "    positive_item_latent, negative_item_latent, user_latent = X\n",
    "\n",
    "    # BPR loss\n",
    "    loss = 1.0 - K.sigmoid(\n",
    "        K.sum(user_latent * positive_item_latent, axis=-1, keepdims=True) -\n",
    "        K.sum(user_latent * negative_item_latent, axis=-1, keepdims=True))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def euclid_triplet_loss(X, margin=0.2):\n",
    "    \n",
    "    positive_item_latent, negative_item_latent, user_latent = X\n",
    "    \n",
    "    #Euclid distance triplet loss\n",
    "    loss = K.maximum(K.sum(K.square(user_latent - positive_item_latent), axis=-1, keepdims=True) \n",
    "                     - K.sum(K.square(user_latent - negative_item_latent), axis=-1, keepdims=True) + margin, 0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def get_base_model():\n",
    "    latent_dim = 256\n",
    "#   include_top：whether to include the fully-connected layer at the top of the network.\n",
    "    base_model = ResNet50(weights='imagenet',include_top=False) # use weights='imagenet' locally\n",
    "\n",
    "    # for layer in base_model.layers:\n",
    "    #     layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    dense_1 = Dense(latent_dim)(x)\n",
    "    normalized = Lambda(lambda  x: K.l2_normalize(x,axis=1))(dense_1)\n",
    "#   相当于对这50长度的vector，每个元素取平方，方便后面的距离计算\n",
    "    base_model = Model(base_model.input, normalized, name=\"base_model\")\n",
    "    return base_model\n",
    "\n",
    "def build_model():\n",
    "    base_model = get_base_model()\n",
    "#   input结构变成(256, 256, 3)\n",
    "    positive_example_1 = Input(input_shape+(3,) , name='positive_example_1')\n",
    "    negative_example = Input(input_shape+(3,), name='negative_example')\n",
    "    positive_example_2 = Input(input_shape+(3,), name='positive_example_2')\n",
    "\n",
    "    positive_example_1_out = base_model(positive_example_1)\n",
    "    negative_example_out = base_model(negative_example)\n",
    "    positive_example_2_out = base_model(positive_example_2)\n",
    "\n",
    "#   用triplet loss的方式对三个embedding进行merge,输出是一个sigmoid\n",
    "    loss = merge(\n",
    "        [positive_example_1_out, negative_example_out, positive_example_2_out],\n",
    "        mode=euclid_triplet_loss,\n",
    "        name='loss',\n",
    "        output_shape=(1, ))\n",
    "\n",
    "#     model = Model(\n",
    "#         input=[positive_example_1, negative_example, positive_example_2],\n",
    "#         output=loss)\n",
    "    \n",
    "    # check to see if we are compiling using just a single GPU\n",
    "    if GPU_num <= 1:\n",
    "        print(\"[INFO] training with 1 GPU...\")\n",
    "        model = Model(input=[positive_example_1, negative_example, positive_example_2],output=loss)\n",
    "    # otherwise, we are compiling using multiple GPUs\n",
    "    else:\n",
    "        print(\"[INFO] training with {} GPUs...\".format(GPU_num))\n",
    "\n",
    "        # we'll store a copy of the model on *every* GPU and then combine\n",
    "        # the results from the gradient updates on the CPU\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            # initialize the model\n",
    "            model = Model(input=[positive_example_1, negative_example, positive_example_2],output=loss)\n",
    "\n",
    "        # make the model parallel\n",
    "        model = multi_gpu_model(model, gpus=GPU_num)    \n",
    "        \n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000001))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model_name = \"triplet_model\"\n",
    "\n",
    "file_path = model_name + \"weights.best.hdf5\"\n",
    "\n",
    "\n",
    "\n",
    "def build_inference_model(weight_path=file_path):\n",
    "    base_model = get_base_model()\n",
    "\n",
    "    positive_example_1 = Input(input_shape+(3,) , name='positive_example_1')\n",
    "    negative_example = Input(input_shape+(3,), name='negative_example')\n",
    "    positive_example_2 = Input(input_shape+(3,), name='positive_example_2')\n",
    "\n",
    "    positive_example_1_out = base_model(positive_example_1)\n",
    "    negative_example_out = base_model(negative_example)\n",
    "    positive_example_2_out = base_model(positive_example_2)\n",
    "\n",
    "    loss = merge(\n",
    "        [positive_example_1_out, negative_example_out, positive_example_2_out],\n",
    "        mode=bpr_triplet_loss,\n",
    "        name='loss',\n",
    "        output_shape=(1, ))\n",
    "\n",
    "    model = Model(\n",
    "        input=[positive_example_1, negative_example, positive_example_2],\n",
    "        output=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000001))\n",
    "\n",
    "#   导入前面训练出来的权重\n",
    "    model.load_weights(weight_path)\n",
    "\n",
    "#   base model只包含了把input转为embedding的过程，没有包含后面的triplet loss部分\n",
    "    inference_model = Model(base_model.get_input_at(0), output=base_model.get_output_at(0))\n",
    "    inference_model.compile(loss=\"mse\", optimizer=Adam(0.000001))\n",
    "    print(inference_model.summary())\n",
    "\n",
    "    return inference_model\n",
    "\n",
    "\n",
    "def read_and_resize(filepaths):\n",
    "#   这里不是用的grayscale，而是转成RGB了\n",
    "    im = Image.open((filepath)).convert('RGB')\n",
    "    im = im.resize(input_shape)\n",
    "#   im的shape变成（256， 256， 3）\n",
    "    im_array = np.array(im, dtype=\"uint8\")[..., ::-1] #这个是对RGB进行逆序？？\n",
    "#   转换成float类型\n",
    "    return np.array(im_array / (np.max(im_array)+ 0.001), dtype=\"float32\")\n",
    "\n",
    "\n",
    "def get_image(filepath):\n",
    "    return path_imageArray_mapping[filepath]\n",
    "\n",
    "\n",
    "\n",
    "# 进行小概率的augment\n",
    "def augment(im_array):\n",
    "    if np.random.uniform(0, 1) > 0.9:\n",
    "#       fliplr只对第1维度column进行flip\n",
    "        im_array = np.fliplr(im_array)\n",
    "    return im_array\n",
    "\n",
    "\n",
    "datagen_args = dict(rotation_range=10,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True)\n",
    "\n",
    "datagen = ImageDataGenerator(**datagen_args)\n",
    "\n",
    "# 进行大概率的augment，更复杂\n",
    "def augment_v2(im_array):\n",
    "    if np.random.uniform(0, 1) > 0.25:\n",
    "        im_array = datagen.random_transform(im_array)\n",
    "    return im_array\n",
    "\n",
    "# 这个函数返回一个generator\n",
    "def gen(triplet_gen):\n",
    "    while True:\n",
    "        list_positive_examples_1 = []\n",
    "        list_negative_examples = []\n",
    "        list_positive_examples_2 = []\n",
    "\n",
    "#       会有重复抽样 bootstrap\n",
    "        for i in range(batch_size):\n",
    "            positive_example_1, negative_example, positive_example_2 = triplet_gen.get_sample()\n",
    "            positive_example_1_img, negative_example_img, positive_example_2_img = get_image(base_path+positive_example_1), \\\n",
    "                                                                       get_image(base_path+negative_example), \\\n",
    "                                                                       get_image(base_path+positive_example_2)\n",
    "#           这个增强并没有增加训练样本数，而是替换了原样本\n",
    "            positive_example_1_img, negative_example_img, positive_example_2_img = augment_v2(positive_example_1_img), \\\n",
    "                                                                                   augment_v2(negative_example_img), \\\n",
    "                                                                                   augment_v2(positive_example_2_img)\n",
    "\n",
    "            list_positive_examples_1.append(positive_example_1_img)\n",
    "            list_negative_examples.append(negative_example_img)\n",
    "            list_positive_examples_2.append(positive_example_2_img)\n",
    "\n",
    "        list_positive_examples_1 = np.array(list_positive_examples_1)\n",
    "        list_negative_examples = np.array(list_negative_examples)\n",
    "        list_positive_examples_2 = np.array(list_positive_examples_2)\n",
    "        \n",
    "#       利用yield，返回一个generator, 并且call on the fly (通过yield + while True)，节省内存\n",
    "#       注意配合model.fit_generator使用的generator返回值必须是（input, target），所以后面的np.ones(batch_size)相当于target (即label)\n",
    "#       只不过在这个模型里面这个target没有被用上而已\n",
    "#       最后注意每次yield返回一个batch的samples\n",
    "        yield [list_positive_examples_1, list_negative_examples, list_positive_examples_2], np.ones(batch_size)\n",
    "\n",
    "    \n",
    "def sort_by_anchor_negative_distance(anchor_examples, negative_examples, positive_examples, latest_model):\n",
    "    lastest_saved_path = 'triplet_modelweights.best.hdf5'\n",
    "    if os.path.isfile(lastest_saved_path):\n",
    "#         latest_model = build_inference_model()\n",
    "        \n",
    "        distances = []\n",
    "        anchor_embeddings = latest_model.predict(np.array(anchor_examples), batch_size=2)\n",
    "        negative_embeddings = latest_model.predict(np.array(negative_examples), batch_size=2)\n",
    "        for i in range(anchor_embeddings.shape[0]):\n",
    "#             anchor_embedding = anchor_embeddings[i]\n",
    "#             negative_embedding = negative_embeddings[i]\n",
    "            distances.append(np.sum(np.square(anchor_embeddings[i] - negative_embeddings[i])))\n",
    "            \n",
    "        values = []\n",
    "        for anchor, negative, positive, distance in zip(anchor_examples, negative_examples, positive_examples, distances):\n",
    "            values.append((anchor, negative, positive, distance))\n",
    "        \n",
    "        dtype = [('anchor', np.float32), ('negative', np.float32), ('positive', np.float32), ('distance', np.float32)]\n",
    "        values_array = np.array(values, dtype=dtype)\n",
    "        array_sorted = np.sort(values_array, order='distance')\n",
    "        \n",
    "        anchor_examples_sort = []\n",
    "        negative_examples_sort = []\n",
    "        positive_examples_sort = []\n",
    "        \n",
    "        for i in range(array_sorted.shape[0]):\n",
    "            anchor_examples_sort.append(array_sorted[i][0])\n",
    "            negative_examples_sort.append(array_sorted[i][1])\n",
    "            positive_examples_sort.append(array_sorted[i][2])\n",
    "        return np.array(anchor_examples_sort), np.array(negative_examples_sort), np.array(positive_examples_sort)\n",
    "    else:\n",
    "        return np.array(anchor_examples), np.array(negative_examples), np.array(positive_examples)\n",
    "    \n",
    "# 这个函数返回一个generator\n",
    "# 使用了“FaceNet: A Unified Embedding for Face Recognition and Clustering” 推荐的online hard triplets selection方法\n",
    "# 用一个latest best model来做筛选，但只对hard negative进行筛选 (semi-hard)\n",
    "def gen_with_online_selection(triplet_gen, latest_model, batch_candidates=30, cutoff=0.5):\n",
    "    while True:\n",
    "        list_positive_examples_1 = []\n",
    "        list_negative_examples = []\n",
    "        list_positive_examples_2 = []\n",
    "        \n",
    "        \n",
    "#       会有重复抽样\n",
    "#       随机筛选30个triplets作为candidates，然后从中选取\n",
    "        for i in range(batch_candidates):\n",
    "            positive_example_1, negative_example, positive_example_2 = triplet_gen.get_sample()\n",
    "            positive_example_1_img, negative_example_img, positive_example_2_img = read_and_resize(base_path+positive_example_1), \\\n",
    "                                                                       read_and_resize(base_path+negative_example), \\\n",
    "                                                                       read_and_resize(base_path+positive_example_2)\n",
    "#           这个增强并没有增加训练样本数，而是替换了原样本\n",
    "            positive_example_1_img, negative_example_img, positive_example_2_img = augment_v2(positive_example_1_img), \\\n",
    "                                                                                   augment_v2(negative_example_img), \\\n",
    "                                                                                   augment_v2(positive_example_2_img)\n",
    "\n",
    "            list_positive_examples_1.append(positive_example_1_img)\n",
    "            list_negative_examples.append(negative_example_img)\n",
    "            list_positive_examples_2.append(positive_example_2_img)\n",
    "\n",
    "#         list_positive_examples_1 = np.array(list_positive_examples_1)\n",
    "#         list_negative_examples = np.array(list_negative_examples)\n",
    "#         list_positive_examples_2 = np.array(list_positive_examples_2)\n",
    "        \n",
    "        list_positive_examples_1, list_negative_examples, list_positive_examples_2 = \\\n",
    "        sort_by_anchor_negative_distance(list_positive_examples_1, list_negative_examples, list_positive_examples_2, latest_model)\n",
    "        \n",
    "#       从最小的(cutoff=50%)anchor-negative distance examples中，随机选取batch_size个examples用来训练模型\n",
    "        idx = np.random.permutation(int(batch_candidates * cutoff))[:batch_size]\n",
    "        \n",
    "#       利用yield，返回一个generator, 并且call on the fly (通过yield + while True)，节省内存\n",
    "#       注意配合model.fit_generator使用的generator返回值必须是（input, target），所以后面的np.ones(batch_size)相当于target (即label)\n",
    "#       只不过在这个模型里面这个target没有被用上而已\n",
    "#       最后注意每次yield返回一个batch的samples\n",
    "        yield [list_positive_examples_1[idx], list_negative_examples[idx], list_positive_examples_2[idx]], np.ones(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum= 1.0\n",
      "sum= 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv('./data/whale/train.csv')\n",
    "train, test = train_test_split(data, test_size=0.3, shuffle=True, random_state=1337)\n",
    "#把image作为key，id作为value\n",
    "file_id_mapping_train = {k: v for k, v in zip(train.Image.values, train.Id.values)}\n",
    "file_id_mapping_test = {k: v for k, v in zip(test.Image.values, test.Id.values)}\n",
    "train_gen = sample_gen(file_id_mapping_train)\n",
    "test_gen = sample_gen(file_id_mapping_test)\n",
    "\n",
    "\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:106: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:115: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"lo..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training with 1 GPU...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "positive_example_1 (InputLayer) (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_example (InputLayer)   (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_example_2 (InputLayer) (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Model)              (None, 256)          24112256    positive_example_1[0][0]         \n",
      "                                                                 negative_example[0][0]           \n",
      "                                                                 positive_example_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "loss (Merge)                    (None, 1)            0           base_model[1][0]                 \n",
      "                                                                 base_model[2][0]                 \n",
      "                                                                 base_model[3][0]                 \n",
      "==================================================================================================\n",
      "Total params: 24,112,256\n",
      "Trainable params: 24,059,136\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      " - 53s - loss: 0.0730 - val_loss: 0.0376\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03755, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 2/300\n",
      " - 24s - loss: 0.0718 - val_loss: 0.0318\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03755 to 0.03180, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 3/300\n",
      " - 24s - loss: 0.0700 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03180 to 0.01390, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 4/300\n",
      " - 24s - loss: 0.0790 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01390 to 0.00000, saving model to triplet_modelweights.best.hdf5\n",
      "Epoch 5/300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0a6ed44ebf62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 这种模式，generate bath on the fly，可以节省很多memory，因而可以使用更大的batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m history = model.fit_generator(gen(train_gen), validation_data=gen(test_gen), epochs=num_epochs, verbose=2, workers=1, use_multiprocessing=False,\n\u001b[0;32m---> 19\u001b[0;31m                               callbacks=callbacks_list, steps_per_epoch=50, validation_steps=1)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/algo/yifeng/tensorflow/tf-env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/algo/yifeng/tensorflow/tf-env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/algo/yifeng/tensorflow/tf-env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/algo/yifeng/tensorflow/tf-env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/algo/yifeng/tensorflow/tf-env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/algo/yifeng/tensorflow/tf-env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Prepare the test triplets\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "\n",
    "#model.load_weights(file_path)\n",
    "\n",
    "# 根据monitor的值即loss，保存loss最小(min)时的model (best model)\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=15)\n",
    "\n",
    "callbacks_list = [checkpoint, early]  # early\n",
    "\n",
    "# Trains the model on data generated batch-by-batch by a Python generator\n",
    "# 这种模式，generate bath on the fly，可以节省很多memory，因而可以使用更大的batch size\n",
    "history = model.fit_generator(gen(train_gen), validation_data=gen(test_gen), epochs=num_epochs, verbose=2, workers=1, use_multiprocessing=False,\n",
    "                              callbacks=callbacks_list, steps_per_epoch=50, validation_steps=1)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"triplet_loss\"\n",
    "def data_generator(fpaths, batch=16):\n",
    "    i = 0\n",
    "    for path in fpaths:\n",
    "        if i == 0:\n",
    "            imgs = []\n",
    "            fnames = []\n",
    "        i += 1\n",
    "        img = read_and_resize(path)\n",
    "        imgs.append(img)\n",
    "#       获取image的名字\n",
    "        fnames.append(os.path.basename(path))\n",
    "        if i == batch:\n",
    "            i = 0\n",
    "            imgs = np.array(imgs)\n",
    "#           每次yield返回一个batch的samples\n",
    "            yield fnames, imgs\n",
    "    if i < batch:\n",
    "        imgs = np.array(imgs)\n",
    "        yield fnames, imgs\n",
    "    raise StopIteration()\n",
    "\n",
    "data = pd.read_csv('./data/whale/train.csv')\n",
    "\n",
    "file_id_mapping = {k: v for k, v in zip(data.Image.values, data.Id.values)}\n",
    "\n",
    "inference_model = build_inference_model()\n",
    "\n",
    "# 文件名匹配，返回一个list包含所有这个后缀的文件path\n",
    "train_files = glob.glob(\"./data/whale/train_full/*.jpg\")\n",
    "test_files = glob.glob(\"./data/whale/test/*.jpg\")\n",
    "\n",
    "train_preds = []\n",
    "train_file_names = []\n",
    "i = 1\n",
    "# 每个imgs里面包含的是一个batch的samples\n",
    "for fnames, imgs in data_generator(train_files, batch=32):\n",
    "#     print(i*32/len(train_files)*100)\n",
    "    i += 1\n",
    "    predicts = inference_model.predict(imgs)\n",
    "#   将一个batch的images转换成embeddings，然后转成list\n",
    "    predicts = predicts.tolist()\n",
    "    train_preds += predicts\n",
    "    train_file_names += fnames\n",
    "\n",
    "#  得到了所有train images的embeddings\n",
    "train_preds = np.array(train_preds)\n",
    "\n",
    "test_preds = []\n",
    "test_file_names = []\n",
    "i = 1\n",
    "for fnames, imgs in data_generator(test_files, batch=32):\n",
    "#     print(i * 32 / len(test_files) * 100)\n",
    "    i += 1\n",
    "    predicts = inference_model.predict(imgs)\n",
    "    predicts = predicts.tolist()\n",
    "    test_preds += predicts\n",
    "    test_file_names += fnames\n",
    "\n",
    "#  得到了所有test images的embeddings\n",
    "test_preds = np.array(test_preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 这里用欧式距离判断class id，并且选取了6个neighbors\n",
    "neigh = NearestNeighbors(n_neighbors=6)\n",
    "neigh.fit(train_preds)\n",
    "#distances, neighbors = neigh.kneighbors(train_preds)\n",
    "\n",
    "#print(distances, neighbors)\n",
    "\n",
    "# 对每个test样本，返回最近的六个embeddings,注意neighbors_test是train_preds里面样本的Index，而非样本本身\n",
    "distances_test, neighbors_test = neigh.kneighbors(test_preds)\n",
    "\n",
    "distances_test, neighbors_test = distances_test.tolist(), neighbors_test.tolist()\n",
    "\n",
    "preds_str = []\n",
    "\n",
    "for filepath, distance, neighbour_ in zip(test_file_names, distances_test, neighbors_test):\n",
    "    sample_result = []\n",
    "    sample_classes = []\n",
    "    for d, n in zip(distance, neighbour_):\n",
    "        train_file = train_files[n].split(os.sep)[-1]\n",
    "        class_train = file_id_mapping[train_file]\n",
    "        sample_classes.append(class_train)\n",
    "        sample_result.append((class_train, d))\n",
    "\n",
    "    if \"new_whale\" not in sample_classes:\n",
    "        sample_result.append((\"new_whale\", 0.09))#new_whale有大概率出现，距离设置为0.1\n",
    "    sample_result.sort(key=lambda x: x[1])\n",
    "    sample_result = sample_result[:5] #取前五个距离最小的预测值\n",
    "    preds_str.append(\" \".join([x[0] for x in sample_result]))\n",
    "\n",
    "df = pd.DataFrame(preds_str, columns=[\"Id\"])\n",
    "df['Image'] = [x.split(os.sep)[-1] for x in test_file_names]\n",
    "df.to_csv(\"sub_%s.csv\"%model_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
